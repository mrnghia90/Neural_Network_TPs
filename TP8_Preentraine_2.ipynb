{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd7ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73dd9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image file and set the resolution\n",
    "photos = np.load('Cats_Dogs_photos.npy')\n",
    "labels = np.load('Cats_Dogs_labels.npy')\n",
    "\n",
    "X_train = photos[:1600,:,:,:]\n",
    "X_test = photos[1600:,:,:,:]\n",
    "y_train = labels[:1600]\n",
    "y_test = labels[1600:]\n",
    "\n",
    "# preprocessing input\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "X_train = preprocess_input(X_train)\n",
    "X_test = preprocess_input(X_test)\n",
    "\n",
    "# load the convolutional base model and set layers as not trainable\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "base_model = MobileNetV2(include_top = False, input_shape = (192,192,3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90967660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25/25 [==============================] - 23s 823ms/step - loss: 1.0840 - accuracy: 0.8489 - val_loss: 0.1377 - val_accuracy: 0.9825\n",
      "Epoch 2/4\n",
      "25/25 [==============================] - 19s 777ms/step - loss: 0.0252 - accuracy: 0.9935 - val_loss: 0.1144 - val_accuracy: 0.9825\n",
      "Epoch 3/4\n",
      "25/25 [==============================] - 19s 790ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1495 - val_accuracy: 0.9800\n",
      "Epoch 4/4\n",
      "25/25 [==============================] - 20s 791ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.1360 - val_accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f38b19df130>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new classifier layers\n",
    "x = Flatten()(base_model.layers[-1].output)\n",
    "x = Dense(128, activation = 'relu', kernel_initializer = 'he_uniform')(x)\n",
    "output = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "# define new model, compile, fit\n",
    "model = Model(inputs = base_model.inputs, outputs = output)\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, epochs = 4, batch_size = 64, validation_data =(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4219d3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999989]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import tensorflow\n",
    "image = load_img('linhmieu.jpg', target_size = (192,192,3))\n",
    "image = img_to_array(image)\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "image = preprocess_input(image)\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import decode_predictions\n",
    "pred = model.predict(image)\n",
    "\n",
    "# pred = 0 => it is a dog\n",
    "# pred = 1 => it is a cat\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df3f0946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25/25 [==============================] - 14s 550ms/step - loss: 1.3554 - accuracy: 0.5370 - val_loss: 0.6388 - val_accuracy: 0.5925\n",
      "Epoch 2/4\n",
      "25/25 [==============================] - 14s 542ms/step - loss: 0.6049 - accuracy: 0.6454 - val_loss: 0.6240 - val_accuracy: 0.6350\n",
      "Epoch 3/4\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 0.5340 - accuracy: 0.7320 - val_loss: 0.6101 - val_accuracy: 0.6600\n",
      "Epoch 4/4\n",
      "25/25 [==============================] - 13s 519ms/step - loss: 0.4265 - accuracy: 0.8206 - val_loss: 0.6026 - val_accuracy: 0.6725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f382c6a60d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "x0 = Input(shape = (192,192,3))\n",
    "\n",
    "x1 = layers.Conv2D(32,(3,3), strides = (1,1),activation  = 'relu', input_shape = (192,192,3))(x0)\n",
    "x2 = layers.MaxPooling2D((2,2))(x1)\n",
    "\n",
    "x3 = layers.Conv2D(64,(3,3), strides = (1,1),activation = 'relu')(x2)\n",
    "x4 = layers.MaxPooling2D((2,2))(x3)\n",
    "\n",
    "x5 = layers.Flatten()(x4)\n",
    "\n",
    "x6 = layers.Dense(64, activation = 'relu')(x5)\n",
    "x7 = layers.Dense(1, activation = 'sigmoid')(x6)\n",
    "\n",
    "model1 = Model(inputs = x0, outputs = x7)\n",
    "\n",
    "model1.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "model1.fit(X_train,y_train,epochs = 4, batch_size = 64,\n",
    "                 validation_data = (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e5babc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74840367]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1 = model1.predict(image)\n",
    "\n",
    "# pred = 0 => it is a dog\n",
    "# pred = 1 => it is a cat\n",
    "pred1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f2677",
   "metadata": {},
   "source": [
    "On comparare notre résultat et le résultat par un réseau pré-entrainé.\n",
    "On remarque le niveau de précision de pré-entrainé apport une taux de 99.99% pourtant notre réseau dont 74,8%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
